{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba93fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (from seqeval) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9b9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee203ae",
   "metadata": {},
   "source": [
    "### `CNN Classification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9464fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 128\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a0109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_PATH = \"w2v_med_cbow.model\"\n",
    "\n",
    "TRAIN_FILES = [\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/MEDLINE/MEDLINEtrain_layer1_ID.csv\",\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/EMEA/EMEAtrain_layer1_ID.csv\",\n",
    "]\n",
    "VALID_FILES = [\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/MEDLINE/MEDLINEdev_layer1_ID.csv\",\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/EMEA/EMEAdev_layer1_ID.csv\",\n",
    "]\n",
    "TEST_FILES = [\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/MEDLINE/MEDLINEtest_layer1_ID.csv\",\n",
    "    \"TP_ISD2020/QUAERO_FrenchMed/EMEA/EMEAtest_layer1_ID.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad480860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOADING DATA ---\n",
      "Loading MEDLINEtrain_layer1_ID.csv... -> 91 sentences.\n",
      "Loading EMEAtrain_layer1_ID.csv... -> 120 sentences.\n",
      "Loading MEDLINEdev_layer1_ID.csv... -> 90 sentences.\n",
      "Loading EMEAdev_layer1_ID.csv... -> 106 sentences.\n",
      "Loading MEDLINEtest_layer1_ID.csv... -> 94 sentences.\n",
      "Loading EMEAtest_layer1_ID.csv... -> 97 sentences.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. ROBUST DATA LOADER ---\n",
    "def load_data_from_csv(file_paths):\n",
    "    all_sentences = []\n",
    "    all_tags = []\n",
    "\n",
    "    for fpath in file_paths:\n",
    "        if not os.path.exists(fpath):\n",
    "            print(f\"❌ File not found: {fpath}\")\n",
    "            continue\n",
    "        print(f\"Loading {os.path.basename(fpath)}...\", end=\" \")\n",
    "\n",
    "        try:\n",
    "            # key: skip_blank_lines=False preserves sentence separators\n",
    "            df = pd.read_csv(\n",
    "                fpath,\n",
    "                sep=None,\n",
    "                engine=\"python\",\n",
    "                keep_default_na=False,\n",
    "                skip_blank_lines=False,\n",
    "            )\n",
    "        except:\n",
    "            print(\"Read Failed.\")\n",
    "            continue\n",
    "\n",
    "        # Detect columns\n",
    "        if \"Mot\" in df.columns and \"Tag\" in df.columns:\n",
    "            words, tags = df[\"Mot\"].astype(str).values, df[\"Tag\"].astype(str).values\n",
    "        else:\n",
    "            words, tags = (\n",
    "                df.iloc[:, 0].astype(str).values,\n",
    "                df.iloc[:, -1].astype(str).values,\n",
    "            )\n",
    "\n",
    "        curr_s, curr_t = [], []\n",
    "        file_s, file_t = [], []\n",
    "\n",
    "        for w, t in zip(words, tags):\n",
    "            if not w.strip():  # Empty line = Sentence Break\n",
    "                if curr_s:\n",
    "                    file_s.append(curr_s)\n",
    "                    file_t.append(curr_t)\n",
    "                    curr_s, curr_t = [], []\n",
    "            else:\n",
    "                curr_s.append(w)\n",
    "                curr_t.append(t)\n",
    "        if curr_s:\n",
    "            file_s.append(curr_s)\n",
    "            file_t.append(curr_t)\n",
    "\n",
    "        # Fallback for giant files (Chunking)\n",
    "        if len(file_s) < 10 and len(words) > 500:\n",
    "            flat_w = [w for s in file_s for w in s]\n",
    "            flat_t = [t for s in file_t for t in s]\n",
    "            file_s = [\n",
    "                flat_w[i : i + SEQUENCE_LENGTH]\n",
    "                for i in range(0, len(flat_w), SEQUENCE_LENGTH)\n",
    "            ]\n",
    "            file_t = [\n",
    "                flat_t[i : i + SEQUENCE_LENGTH]\n",
    "                for i in range(0, len(flat_t), SEQUENCE_LENGTH)\n",
    "            ]\n",
    "\n",
    "        print(f\"-> {len(file_s)} sentences.\")\n",
    "        all_sentences.extend(file_s)\n",
    "        all_tags.extend(file_t)\n",
    "\n",
    "    return all_sentences, all_tags\n",
    "\n",
    "\n",
    "print(\"--- LOADING DATA ---\")\n",
    "train_sents, train_tags = load_data_from_csv(TRAIN_FILES)\n",
    "valid_sents, valid_tags = load_data_from_csv(VALID_FILES)\n",
    "test_sents, test_tags = load_data_from_csv(TEST_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687b3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INITIALIZING EMBEDDINGS ---\n",
      "Vocab Size: 5775\n",
      "Pre-trained Weights Found: 5621/5775 (97.3%)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. BUILD VOCAB & INITIALIZE EMBEDDINGS (TP1) ---\n",
    "print(\"\\n--- INITIALIZING EMBEDDINGS ---\")\n",
    "\n",
    "# A. Build Vocabulary from Training Data\n",
    "word_counts = {}\n",
    "for sent in train_sents:\n",
    "    for word in sent:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "word2idx = {w: i + 2 for i, w in enumerate(vocab)}  # Start at 2\n",
    "word2idx[\"<PAD>\"] = 0\n",
    "word2idx[\"<UNK>\"] = 1\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "# B. Load Word2Vec and Create Weight Matrix\n",
    "w2v_model = Word2Vec.load(W2V_PATH)\n",
    "vocab_size = len(word2idx)\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "hits = 0\n",
    "\n",
    "for word, idx in word2idx.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word]\n",
    "        hits += 1\n",
    "    elif word.lower() in w2v_model.wv:  # Case Insensitive Fallback\n",
    "        embedding_matrix[idx] = w2v_model.wv[word.lower()]\n",
    "        hits += 1\n",
    "    else:\n",
    "        # Initialize OOV words with random noise\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "print(f\"Vocab Size: {vocab_size}\")\n",
    "print(f\"Pre-trained Weights Found: {hits}/{vocab_size} ({hits/vocab_size:.1%})\")\n",
    "\n",
    "# Convert to FloatTensor\n",
    "embedding_weights = torch.tensor(embedding_matrix, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60b213c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: {'B-ANAT': 1, 'B-CHEM': 2, 'B-DEVI': 3, 'B-DISO': 4, 'B-GEOG': 5, 'B-LIVB': 6, 'B-OBJC': 7, 'B-PHEN': 8, 'B-PHYS': 9, 'B-PROC': 10, 'I-ANAT': 11, 'I-CHEM': 12, 'I-DEVI': 13, 'I-DISO': 14, 'I-GEOG': 15, 'I-LIVB': 16, 'I-OBJC': 17, 'I-PHEN': 18, 'I-PHYS': 19, 'I-PROC': 20, 'O': 21, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "# --- 4. DATA PREPARATION (ENCODING) ---\n",
    "def encode_sequences(seqs, mapping, default_val, max_len=128):\n",
    "    encoded = []\n",
    "    for s in seqs:\n",
    "        seq = [mapping.get(item, default_val) for item in s]\n",
    "        if len(seq) < max_len:\n",
    "            seq += [0] * (max_len - len(seq))\n",
    "        else:\n",
    "            seq = seq[:max_len]\n",
    "        encoded.append(seq)\n",
    "    return torch.tensor(encoded, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Encode Words (Input)\n",
    "X_train = encode_sequences(train_sents, word2idx, 1)  # 1 = UNK\n",
    "X_valid = encode_sequences(valid_sents, word2idx, 1)\n",
    "X_test = encode_sequences(test_sents, word2idx, 1)\n",
    "\n",
    "# Encode Tags (Target)\n",
    "tag_set = set(t for s in train_tags + valid_tags + test_tags for t in s)\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(sorted(list(tag_set)))}\n",
    "tag2idx[\"<PAD>\"] = 0\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}\n",
    "print(f\"Tags: {tag2idx}\")\n",
    "\n",
    "y_train = encode_sequences(train_tags, tag2idx, 0)  # 0 = PAD (ignored in loss)\n",
    "y_valid = encode_sequences(valid_tags, tag2idx, 0)\n",
    "y_test = encode_sequences(test_tags, tag2idx, 0)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train), shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    TensorDataset(X_valid, y_valid), shuffle=False, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test, y_test), shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "388e0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. CNN MODEL ---\n",
    "class CNN_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, pretrained_weights):\n",
    "        super(CNN_NER, self).__init__()\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        # INITIALIZATION: Overwrite with TP1 weights\n",
    "        self.embedding.weight.data.copy_(pretrained_weights)\n",
    "\n",
    "        # CNN Layers (Conv1d preserves sequence length with padding=1)\n",
    "        self.conv1 = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [Batch, Seq, Dim]\n",
    "        x = x.permute(0, 2, 1)  # [Batch, Dim, Seq] (Required for Conv1d)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # [Batch, Seq, 256]\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "model = CNN_NER(vocab_size, EMBEDDING_DIM, len(tag2idx), embedding_weights).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28085613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING TRAINING ON cpu ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 7/7 [00:00<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4237 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8451 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6470 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5300 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 7/7 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4783 | Val F1: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4026 | Val F1: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 7/7 [00:00<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3379 | Val F1: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 7/7 [00:00<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2781 | Val F1: 0.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2236 | Val F1: 0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 7/7 [00:00<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1716 | Val F1: 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 7/7 [00:00<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1204 | Val F1: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0843 | Val F1: 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 7/7 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0354 | Val F1: 0.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 7/7 [00:00<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9928 | Val F1: 0.2835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9409 | Val F1: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 7/7 [00:00<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8900 | Val F1: 0.3039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 7/7 [00:00<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8512 | Val F1: 0.3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 7/7 [00:00<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8164 | Val F1: 0.3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7774 | Val F1: 0.3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 7/7 [00:00<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7389 | Val F1: 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 7/7 [00:00<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7068 | Val F1: 0.3317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 7/7 [00:00<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6816 | Val F1: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 7/7 [00:01<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6366 | Val F1: 0.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:00<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6183 | Val F1: 0.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5839 | Val F1: 0.3544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 7/7 [00:00<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5563 | Val F1: 0.3575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 7/7 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5295 | Val F1: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 7/7 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5007 | Val F1: 0.3637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 7/7 [00:00<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4785 | Val F1: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 7/7 [00:00<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4592 | Val F1: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 7/7 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4325 | Val F1: 0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 7/7 [00:00<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4126 | Val F1: 0.3664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 7/7 [00:00<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3905 | Val F1: 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 7/7 [00:00<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3691 | Val F1: 0.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 7/7 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3543 | Val F1: 0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 7/7 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3307 | Val F1: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 7/7 [00:00<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223 | Val F1: 0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 7/7 [00:00<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3027 | Val F1: 0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 7/7 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2829 | Val F1: 0.3781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 7/7 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2845 | Val F1: 0.3751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 7/7 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2694 | Val F1: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 7/7 [00:00<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2554 | Val F1: 0.3810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 7/7 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2475 | Val F1: 0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 7/7 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2388 | Val F1: 0.3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 7/7 [00:00<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2268 | Val F1: 0.3716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2115 | Val F1: 0.3772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2044 | Val F1: 0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 7/7 [00:00<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2018 | Val F1: 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1954 | Val F1: 0.3810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1849 | Val F1: 0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1795 | Val F1: 0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 7/7 [00:00<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1724 | Val F1: 0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1692 | Val F1: 0.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1660 | Val F1: 0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 7/7 [00:00<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1555 | Val F1: 0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 7/7 [00:00<00:00, 11.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1544 | Val F1: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 7/7 [00:00<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1474 | Val F1: 0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 7/7 [00:00<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1420 | Val F1: 0.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 7/7 [00:00<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1395 | Val F1: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1339 | Val F1: 0.3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 7/7 [00:00<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1322 | Val F1: 0.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 7/7 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1250 | Val F1: 0.3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 7/7 [00:00<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1231 | Val F1: 0.3783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 7/7 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1168 | Val F1: 0.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 7/7 [00:00<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1133 | Val F1: 0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 7/7 [00:00<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1113 | Val F1: 0.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 7/7 [00:00<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1060 | Val F1: 0.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1030 | Val F1: 0.3702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 7/7 [00:00<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1012 | Val F1: 0.3709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0975 | Val F1: 0.3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 7/7 [00:00<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0968 | Val F1: 0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0951 | Val F1: 0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 7/7 [00:00<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0964 | Val F1: 0.3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 7/7 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0871 | Val F1: 0.3662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 7/7 [00:00<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0892 | Val F1: 0.3672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 7/7 [00:00<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0895 | Val F1: 0.3728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 7/7 [00:00<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0817 | Val F1: 0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 7/7 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0811 | Val F1: 0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 7/7 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0803 | Val F1: 0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0768 | Val F1: 0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 7/7 [00:00<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0748 | Val F1: 0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0720 | Val F1: 0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 7/7 [00:00<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0748 | Val F1: 0.3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0701 | Val F1: 0.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 7/7 [00:00<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0723 | Val F1: 0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0686 | Val F1: 0.3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0664 | Val F1: 0.3710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 7/7 [00:00<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0668 | Val F1: 0.3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 7/7 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0628 | Val F1: 0.3732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 7/7 [00:00<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0633 | Val F1: 0.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0595 | Val F1: 0.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 7/7 [00:00<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0598 | Val F1: 0.3737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 7/7 [00:00<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0591 | Val F1: 0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 7/7 [00:00<00:00, 11.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0550 | Val F1: 0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 7/7 [00:00<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0578 | Val F1: 0.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 7/7 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0551 | Val F1: 0.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 7/7 [00:00<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0539 | Val F1: 0.3788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0534 | Val F1: 0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 7/7 [00:00<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0499 | Val F1: 0.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 7/7 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0502 | Val F1: 0.3780\n"
     ]
    }
   ],
   "source": [
    "# --- 6. TRAINING ---\n",
    "# Weighted Loss for \"O\" Class Imbalance\n",
    "weights = torch.ones(len(tag2idx)).to(DEVICE)\n",
    "if \"O\" in tag2idx:\n",
    "    weights[tag2idx[\"O\"]] = 0.5\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, ignore_index=0)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\n--- STARTING TRAINING ON {DEVICE} ---\")\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out.view(-1, len(tag2idx)), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x)\n",
    "            preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "            labels = y.cpu().numpy()\n",
    "\n",
    "            for i in range(len(x)):\n",
    "                p_s, t_s = [], []\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    if labels[i][j] == 0:\n",
    "                        break  # Stop at PAD\n",
    "                    p_s.append(idx2tag[preds[i][j]])\n",
    "                    t_s.append(idx2tag[labels[i][j]])\n",
    "                all_pred.append(p_s)\n",
    "                all_true.append(t_s)\n",
    "\n",
    "    val_f1 = f1_score(all_true, all_pred)\n",
    "    print(f\"Loss: {train_loss/len(train_loader):.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_cnn_ner.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f03cf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST RESULTS ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ANAT       0.38      0.24      0.30       364\n",
      "        CHEM       0.45      0.19      0.27      1037\n",
      "        DEVI       0.15      0.04      0.06       107\n",
      "        DISO       0.35      0.24      0.29       977\n",
      "        GEOG       0.50      0.05      0.09        63\n",
      "        LIVB       0.75      0.57      0.65       498\n",
      "        OBJC       0.14      0.04      0.06        81\n",
      "        PHEN       0.00      0.00      0.00        70\n",
      "        PHYS       0.48      0.21      0.29       190\n",
      "        PROC       0.41      0.49      0.45       761\n",
      "\n",
      "   micro avg       0.44      0.30      0.35      4148\n",
      "   macro avg       0.36      0.21      0.24      4148\n",
      "weighted avg       0.43      0.30      0.34      4148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- 7. FINAL TEST EVALUATION ---\n",
    "print(\"\\n--- TEST RESULTS ---\")\n",
    "model.load_state_dict(torch.load(\"best_cnn_ner.pt\"))\n",
    "model.eval()\n",
    "test_true, test_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        out = model(x)\n",
    "        preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "        labels = y.numpy()\n",
    "        for i in range(len(x)):\n",
    "            p_s, t_s = [], []\n",
    "            for j in range(SEQUENCE_LENGTH):\n",
    "                if labels[i][j] == 0:\n",
    "                    break\n",
    "                p_s.append(idx2tag[preds[i][j]])\n",
    "                t_s.append(idx2tag[labels[i][j]])\n",
    "            test_pred.append(p_s)\n",
    "            test_true.append(t_s)\n",
    "\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c4a19",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527c3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c85124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SWITCHING TO Bi-LSTM ---\n",
      "Vocab Size: 5775\n",
      "Embedding Dim: 100\n"
     ]
    }
   ],
   "source": [
    "# --- 2. CONFIGURATION ---\n",
    "HIDDEN_DIM = 256\n",
    "LSTM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"--- SWITCHING TO Bi-LSTM ---\")\n",
    "print(f\"Vocab Size: {vocab_size}\")\n",
    "print(f\"Embedding Dim: {EMBEDDING_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87059be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Bi-LSTM MODEL DEFINITION ---\n",
    "class LSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, pretrained_weights):\n",
    "        super(LSTM_NER, self).__init__()\n",
    "\n",
    "        # 1. Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "\n",
    "        # Initialize with TP1 Weights (Same as CNN)\n",
    "        self.embedding.weight.data.copy_(pretrained_weights)\n",
    "        # Optional: Unfreeze to allow fine-tuning\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        # 2. Bi-LSTM Layer\n",
    "        # batch_first=True -> Input is (Batch, Seq, Feature)\n",
    "        # bidirectional=True -> Output is Hidden * 2\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # 3. Fully Connected Layer\n",
    "        # Maps from [Hidden * 2] to [Num_Tags]\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, Seq_Len]\n",
    "\n",
    "        # Get Embeddings\n",
    "        embeds = self.embedding(x)\n",
    "        # embeds shape: [Batch, Seq_Len, Embed_Dim]\n",
    "\n",
    "        # LSTM Pass\n",
    "        # No permutation needed here (LSTM expects Batch, Seq, Dim)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        # lstm_out shape: [Batch, Seq_Len, Hidden_Dim * 2]\n",
    "\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # Projection to Tag Space\n",
    "        logits = self.fc(lstm_out)\n",
    "        # logits shape: [Batch, Seq_Len, Num_Classes]\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Initialize Model\n",
    "model = LSTM_NER(vocab_size, EMBEDDING_DIM, HIDDEN_DIM,\n",
    "                 len(tag2idx), embedding_weights).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f717fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.ones(len(tag2idx)).to(DEVICE)\n",
    "if 'O' in tag2idx:\n",
    "    weights[tag2idx['O']] = 0.5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, ignore_index=0)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9241ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING Bi-LSTM TRAINING ON cpu ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 7/7 [00:01<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6434 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 7/7 [00:01<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7925 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 7/7 [00:01<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6682 | Val F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5878 | Val F1: 0.0327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 7/7 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5319 | Val F1: 0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 7/7 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4691 | Val F1: 0.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 7/7 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4125 | Val F1: 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 7/7 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3355 | Val F1: 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2400 | Val F1: 0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 7/7 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1779 | Val F1: 0.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 7/7 [00:01<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0793 | Val F1: 0.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 7/7 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0088 | Val F1: 0.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 7/7 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9331 | Val F1: 0.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8547 | Val F1: 0.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 7/7 [00:01<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7900 | Val F1: 0.3149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 7/7 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7353 | Val F1: 0.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 7/7 [00:01<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6693 | Val F1: 0.3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 7/7 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6166 | Val F1: 0.3345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 7/7 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5672 | Val F1: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 7/7 [00:01<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5261 | Val F1: 0.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 7/7 [00:01<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4845 | Val F1: 0.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 7/7 [00:01<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4434 | Val F1: 0.3544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 7/7 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3991 | Val F1: 0.3554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 7/7 [00:01<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3734 | Val F1: 0.3532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 7/7 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3434 | Val F1: 0.3514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 7/7 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3193 | Val F1: 0.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 7/7 [00:01<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2946 | Val F1: 0.3681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 7/7 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2675 | Val F1: 0.3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 7/7 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2492 | Val F1: 0.3678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 7/7 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2327 | Val F1: 0.3663\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- STARTING Bi-LSTM TRAINING ON {DEVICE} ---\")\n",
    "best_f1 = 0\n",
    "\n",
    "for epoch in range(LSTM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Training Step\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)  # [Batch, Seq, Num_Classes]\n",
    "\n",
    "        # Flatten for Loss: (Batch * Seq, Num_Classes) vs (Batch * Seq)\n",
    "        loss = criterion(out.view(-1, len(tag2idx)), y.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x)\n",
    "\n",
    "            # Get Predictions\n",
    "            preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "            labels = y.cpu().numpy()\n",
    "\n",
    "            # Decode (Remove Padding)\n",
    "            for i in range(len(x)):\n",
    "                p_s, t_s = [], []\n",
    "                for j in range(SEQUENCE_LENGTH):\n",
    "                    if labels[i][j] == 0:\n",
    "                        break  # Stop at padding\n",
    "                    p_s.append(idx2tag[preds[i][j]])\n",
    "                    t_s.append(idx2tag[labels[i][j]])\n",
    "                all_pred.append(p_s)\n",
    "                all_true.append(t_s)\n",
    "\n",
    "    # Metrics\n",
    "    val_f1 = f1_score(all_true, all_pred)\n",
    "    print(f\"Loss: {train_loss/len(train_loader):.4f} | Val F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Save Best\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_lstm_ner.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37b31b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Bi-LSTM TEST RESULTS ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ANAT       0.34      0.13      0.19       364\n",
      "        CHEM       0.26      0.22      0.24      1037\n",
      "        DEVI       0.50      0.01      0.02       107\n",
      "        DISO       0.41      0.28      0.33       977\n",
      "        GEOG       0.00      0.00      0.00        63\n",
      "        LIVB       0.75      0.52      0.62       498\n",
      "        OBJC       0.00      0.00      0.00        81\n",
      "        PHEN       0.00      0.00      0.00        70\n",
      "        PHYS       0.38      0.16      0.22       190\n",
      "        PROC       0.50      0.46      0.48       761\n",
      "\n",
      "   micro avg       0.42      0.29      0.34      4148\n",
      "   macro avg       0.31      0.18      0.21      4148\n",
      "weighted avg       0.40      0.29      0.33      4148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Bi-LSTM TEST RESULTS ---\")\n",
    "model.load_state_dict(torch.load(\"best_lstm_ner.pt\"))\n",
    "model.eval()\n",
    "test_true, test_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        out = model(x)\n",
    "        preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "        labels = y.numpy()\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            p_s, t_s = [], []\n",
    "            for j in range(SEQUENCE_LENGTH):\n",
    "                if labels[i][j] == 0:\n",
    "                    break\n",
    "                p_s.append(idx2tag[preds[i][j]])\n",
    "                t_s.append(idx2tag[labels[i][j]])\n",
    "            test_pred.append(p_s)\n",
    "            test_true.append(t_s)\n",
    "\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367cb0c",
   "metadata": {},
   "source": [
    "### `French Press dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94578fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "from seqeval.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6a2e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURATION ---\n",
    "SEQUENCE_LENGTH = 128\n",
    "EMBEDDING_DIM = 100   # Must match your w2v_press_cbow.model\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PATHS (Press Data & Press Embeddings)\n",
    "W2V_PATH = \"w2v_press_cbow.model\"\n",
    "PRESS_DIR = \"TP_ISD2020/QUAERO_FrenchPress\"\n",
    "\n",
    "TRAIN_FILES = [f\"{PRESS_DIR}/fra4_ID_train.csv\"]\n",
    "VALID_FILES = [f\"{PRESS_DIR}/fra4_ID_dev.csv\"]\n",
    "TEST_FILES = [f\"{PRESS_DIR}/fra4_ID_test.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63be61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOADING PRESS DATA ---\n",
      "Loading fra4_ID_train.csv... -> 9034 sentences.\n",
      "Loading fra4_ID_dev.csv... -> 744 sentences.\n",
      "Loading fra4_ID_test.csv... -> 749 sentences.\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_csv(file_paths):\n",
    "    all_sentences, all_tags = [], []\n",
    "    for fpath in file_paths:\n",
    "        if not os.path.exists(fpath):\n",
    "            continue\n",
    "        print(f\"Loading {os.path.basename(fpath)}...\", end=\" \")\n",
    "        try:\n",
    "            df = pd.read_csv(fpath, sep=None, engine=\"python\",\n",
    "                             keep_default_na=False, skip_blank_lines=False)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if \"Mot\" in df.columns:\n",
    "            words, tags = df[\"Mot\"].astype(\n",
    "                str).values, df[\"Tag\"].astype(str).values\n",
    "        else:\n",
    "            words, tags = df.iloc[:, 0].astype(\n",
    "                str).values, df.iloc[:, -1].astype(str).values\n",
    "\n",
    "        curr_s, curr_t, file_s, file_t = [], [], [], []\n",
    "        for w, t in zip(words, tags):\n",
    "            if not w.strip():\n",
    "                if curr_s:\n",
    "                    file_s.append(curr_s)\n",
    "                    file_t.append(curr_t)\n",
    "                    curr_s, curr_t = [], []\n",
    "            else:\n",
    "                curr_s.append(w)\n",
    "                curr_t.append(t)\n",
    "        if curr_s:\n",
    "            file_s.append(curr_s)\n",
    "            file_t.append(curr_t)\n",
    "\n",
    "        # Chunking\n",
    "        if len(file_s) < 10 and len(words) > 500:\n",
    "            flat_w = [w for s in file_s for w in s]\n",
    "            flat_t = [t for s in file_t for t in s]\n",
    "            file_s = [flat_w[i:i+SEQUENCE_LENGTH]\n",
    "                      for i in range(0, len(flat_w), SEQUENCE_LENGTH)]\n",
    "            file_t = [flat_t[i:i+SEQUENCE_LENGTH]\n",
    "                      for i in range(0, len(flat_t), SEQUENCE_LENGTH)]\n",
    "\n",
    "        print(f\"-> {len(file_s)} sentences.\")\n",
    "        all_sentences.extend(file_s)\n",
    "        all_tags.extend(file_t)\n",
    "    return all_sentences, all_tags\n",
    "\n",
    "\n",
    "print(\"--- LOADING PRESS DATA ---\")\n",
    "train_sents, train_tags = load_data_from_csv(TRAIN_FILES)\n",
    "valid_sents, valid_tags = load_data_from_csv(VALID_FILES)\n",
    "test_sents, test_tags = load_data_from_csv(TEST_FILES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bbf79d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LOADING PRESS EMBEDDINGS ---\n",
      "Vocab: 37865 | Coverage: 99.5%\n"
     ]
    }
   ],
   "source": [
    "# --- 3. PREPARE EMBEDDINGS (PRESS W2V) ---\n",
    "print(\"\\n--- LOADING PRESS EMBEDDINGS ---\")\n",
    "# Build Vocab\n",
    "word_counts = {}\n",
    "for sent in train_sents:\n",
    "    for word in sent:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "word2idx = {w: i+2 for i, w in enumerate(vocab)}\n",
    "word2idx['<PAD>'] = 0\n",
    "word2idx['<UNK>'] = 1\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "# Load Weights\n",
    "w2v_model = Word2Vec.load(W2V_PATH)\n",
    "embedding_matrix = np.zeros((len(word2idx), EMBEDDING_DIM))\n",
    "hits = 0\n",
    "for word, idx in word2idx.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word]\n",
    "        hits += 1\n",
    "    elif word.lower() in w2v_model.wv:\n",
    "        embedding_matrix[idx] = w2v_model.wv[word.lower()]\n",
    "        hits += 1\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(\n",
    "            scale=0.6, size=(EMBEDDING_DIM,))\n",
    "\n",
    "print(f\"Vocab: {len(word2idx)} | Coverage: {hits/len(word2idx):.1%}\")\n",
    "embedding_weights = torch.tensor(\n",
    "    embedding_matrix, dtype=torch.float32).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb5615e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: {'O': 1, 'b-func': 2, 'b-loc': 3, 'b-org': 4, 'b-pers': 5, 'b-prod': 6, 'i-func': 7, 'i-loc': 8, 'i-org': 9, 'i-pers': 10, 'i-prod': 11, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "# --- 4. ENCODE DATA ---\n",
    "def encode_seq(seqs, mapping, default):\n",
    "    enc = []\n",
    "    for s in seqs:\n",
    "        r = [mapping.get(x, default) for x in s]\n",
    "        if len(r) < SEQUENCE_LENGTH:\n",
    "            r += [0]*(SEQUENCE_LENGTH-len(r))\n",
    "        else:\n",
    "            r = r[:SEQUENCE_LENGTH]\n",
    "        enc.append(r)\n",
    "    return torch.tensor(enc, dtype=torch.long)\n",
    "\n",
    "\n",
    "X_train = encode_seq(train_sents, word2idx, 1)\n",
    "X_valid = encode_seq(valid_sents, word2idx, 1)\n",
    "X_test = encode_seq(test_sents,  word2idx, 1)\n",
    "\n",
    "tag_set = set(t for s in train_tags+valid_tags+test_tags for t in s)\n",
    "tag2idx = {t: i+1 for i, t in enumerate(sorted(list(tag_set)))}\n",
    "tag2idx['<PAD>'] = 0\n",
    "idx2tag = {v: k for k, v in tag2idx.items()}\n",
    "print(f\"Tags: {tag2idx}\")\n",
    "\n",
    "y_train = encode_seq(train_tags, tag2idx, 0)\n",
    "y_valid = encode_seq(valid_tags, tag2idx, 0)\n",
    "y_test = encode_seq(test_tags,  tag2idx, 0)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(\n",
    "    X_train, y_train), shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(TensorDataset(\n",
    "    X_valid, y_valid), shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test),\n",
    "                         shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353604f",
   "metadata": {},
   "source": [
    "### `Part A : CNN Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "700e5460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " TRAINING CNN (PRESS)\n",
      "==============================\n",
      "Epoch 15 Complete\n",
      "--- CNN EVALUATION ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: b-prod seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: i-prod seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: b-pers seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: i-pers seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: b-org seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: i-org seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: b-func seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: b-loc seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: i-loc seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/idrissamahamoudoudicko/anaconda3/envs/HandonNLP/lib/python3.13/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: i-func seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        func       0.53      0.47      0.50       624\n",
      "         loc       0.69      0.65      0.67       713\n",
      "         org       0.24      0.45      0.31       505\n",
      "        pers       0.79      0.63      0.70      1377\n",
      "        prod       0.03      0.40      0.06       335\n",
      "\n",
      "   micro avg       0.28      0.56      0.37      3554\n",
      "   macro avg       0.46      0.52      0.45      3554\n",
      "weighted avg       0.58      0.56      0.54      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*30 + \"\\n TRAINING CNN (PRESS)\\n\" + \"=\"*30)\n",
    "\n",
    "\n",
    "class CNN_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, weights):\n",
    "        super(CNN_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(weights)  # Init with Press W2V\n",
    "        self.conv1 = nn.Conv1d(embed_dim, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = self.dropout(\n",
    "            F.relu(self.conv2(self.dropout(F.relu(self.conv1(x))))))\n",
    "        return self.fc(x.permute(0, 2, 1))\n",
    "\n",
    "\n",
    "model_cnn = CNN_NER(len(word2idx), EMBEDDING_DIM, len(\n",
    "    tag2idx), embedding_weights).to(DEVICE)\n",
    "weights = torch.ones(len(tag2idx)).to(DEVICE)\n",
    "if 'O' in tag2idx:\n",
    "    weights[tag2idx['O']] = 0.5\n",
    "opt = Adam(model_cnn.parameters(), lr=LEARNING_RATE)\n",
    "crit = nn.CrossEntropyLoss(weight=weights, ignore_index=0)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    model_cnn.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model_cnn(x).view(-1, len(tag2idx)), y.view(-1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    # Validation info\n",
    "    print(f\"Epoch {e+1} Complete\", end=\"\\r\")\n",
    "\n",
    "print(\"\\n--- CNN EVALUATION ---\")\n",
    "model_cnn.eval()\n",
    "test_true, test_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        out = model_cnn(x.to(DEVICE))\n",
    "        preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "        labels = y.numpy()\n",
    "        for i in range(len(x)):\n",
    "            p_s, t_s = [], []\n",
    "            for j in range(SEQUENCE_LENGTH):\n",
    "                if labels[i][j] == 0:\n",
    "                    break\n",
    "                p_s.append(idx2tag[preds[i][j]])\n",
    "                t_s.append(idx2tag[labels[i][j]])\n",
    "            test_pred.append(p_s)\n",
    "            test_true.append(t_s)\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840f79a",
   "metadata": {},
   "source": [
    "### `PART B: LSTM MODEL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2c30353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " TRAINING LSTM (PRESS)\n",
      "==============================\n",
      "Epoch 15 Complete\n",
      "--- LSTM EVALUATION ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        func       0.15      0.46      0.23       624\n",
      "         loc       0.69      0.65      0.66       713\n",
      "         org       0.24      0.44      0.31       505\n",
      "        pers       0.60      0.56      0.58      1377\n",
      "        prod       0.05      0.32      0.09       335\n",
      "\n",
      "   micro avg       0.27      0.52      0.35      3554\n",
      "   macro avg       0.35      0.49      0.37      3554\n",
      "weighted avg       0.44      0.52      0.45      3554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*30 + \"\\n TRAINING LSTM (PRESS)\\n\" + \"=\"*30)\n",
    "\n",
    "# Cleanup Memory\n",
    "del model_cnn, opt, crit\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "\n",
    "class LSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, weights):\n",
    "        super(LSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(weights)  # Init with Press W2V\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        return self.fc(self.dropout(lstm_out))\n",
    "\n",
    "\n",
    "model_lstm = LSTM_NER(len(word2idx), EMBEDDING_DIM, 256,\n",
    "                      len(tag2idx), embedding_weights).to(DEVICE)\n",
    "opt = Adam(model_lstm.parameters(), lr=LEARNING_RATE)\n",
    "crit = nn.CrossEntropyLoss(weight=weights, ignore_index=0)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    model_lstm.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        loss = crit(model_lstm(x).view(-1, len(tag2idx)), y.view(-1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(f\"Epoch {e+1} Complete\", end=\"\\r\")\n",
    "\n",
    "print(\"\\n--- LSTM EVALUATION ---\")\n",
    "model_lstm.eval()\n",
    "test_true, test_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        out = model_lstm(x.to(DEVICE))\n",
    "        preds = torch.argmax(out, dim=2).cpu().numpy()\n",
    "        labels = y.numpy()\n",
    "        for i in range(len(x)):\n",
    "            p_s, t_s = [], []\n",
    "            for j in range(SEQUENCE_LENGTH):\n",
    "                if labels[i][j] == 0:\n",
    "                    break\n",
    "                p_s.append(idx2tag[preds[i][j]])\n",
    "                t_s.append(idx2tag[labels[i][j]])\n",
    "            test_pred.append(p_s)\n",
    "            test_true.append(t_s)\n",
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d9785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HandonNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
