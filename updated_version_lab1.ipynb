{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ddb586",
   "metadata": {},
   "source": [
    "# `Part 1 : PoS tagging`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cc34db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6f755",
   "metadata": {},
   "source": [
    "ADJ, ADP, AUX, DET, NOUN, NUM, PROPN, PUNCT, SCONJ, VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5baa21",
   "metadata": {},
   "source": [
    "### 1. \"The cat sat on the couch\"\n",
    "This is a grammatically straightforward sentence with no ambiguity.\n",
    "\n",
    "| Word | Tag | Reason |\n",
    "| :--- | :--- | :--- |\n",
    "| **The** | **DET** | Determiner (definite article) |\n",
    "| **cat** | **NOUN** | Common noun |\n",
    "| **sat** | **VERB** | Main verb (past tense) |\n",
    "| **on** | **ADP** | Adposition (preposition) indicating location |\n",
    "| **the** | **DET** | Determiner |\n",
    "| **couch** | **NOUN** | Common noun |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. \"Time flies like an arrow\"\n",
    "\n",
    "This is a classic example of **lexical ambiguity**. While there are joke interpretations (e.g., *Time* as a verb, meaning \"measure the speed of flies\"), the standard reading is annotated below.\n",
    "\n",
    "| Word | Tag | Reason |\n",
    "| :--- | :--- | :--- |\n",
    "| **Time** | **NOUN** | Abstract noun (Subject) |\n",
    "| **flies** | **VERB** | Main verb (Action) |\n",
    "| **like** | **ADP** | Adposition (acting as a preposition here for comparison) |\n",
    "| **an** | **DET** | Determiner (indefinite article) |\n",
    "| **arrow** | **NOUN** | Common noun |\n",
    "\n",
    "> **Note on Ambiguity:** If interpreted as \"Fruit flies [the insect] like [enjoy] a banana,\" *flies* would be a **NOUN** and *like* would be a **VERB**. However, for this specific sentence, the annotation above is the standard English reading.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. \"The spy saw the cop with the telescope\"\n",
    "\n",
    "This sentence contains **structural (attachment) ambiguity**.\n",
    "* *Reading A:* The spy used a telescope to see the cop.\n",
    "* *Reading B:* The spy saw a cop who had a telescope.\n",
    "\n",
    "**However, the POS tags remain the same for both readings:**\n",
    "\n",
    "| Word | Tag | Reason |\n",
    "| :--- | :--- | :--- |\n",
    "| **The** | **DET** | Determiner |\n",
    "| **spy** | **NOUN** | Common noun |\n",
    "| **saw** | **VERB** | Main verb |\n",
    "| **the** | **DET** | Determiner |\n",
    "| **cop** | **NOUN** | Common noun |\n",
    "| **with** | **ADP** | Adposition (preposition) |\n",
    "| **the** | **DET** | Determiner |\n",
    "| **telescope**| **NOUN** | Common noun |\n",
    "\n",
    "---\n",
    "\n",
    "### 4. \"The spy saw the cop with the revolver\"\n",
    "Structurally identical to the sentence above, though semantically we assume the \"revolver\" belongs to the cop (Reading B), as seeing *using* a revolver makes less sense. The tags follow the exact same pattern.\n",
    "\n",
    "| Word | Tag | Reason |\n",
    "| :--- | :--- | :--- |\n",
    "| **The** | **DET** | Determiner |\n",
    "| **spy** | **NOUN** | Common noun |\n",
    "| **saw** | **VERB** | Main verb |\n",
    "| **the** | **DET** | Determiner |\n",
    "| **cop** | **NOUN** | Common noun |\n",
    "| **with** | **ADP** | Adposition (preposition) |\n",
    "| **the** | **DET** | Determiner |\n",
    "| **revolver** | **NOUN** | Common noun |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Tag Usage\n",
    "* **NOUN:** cat, couch, Time, arrow, spy, cop, telescope, revolver\n",
    "* **VERB:** sat, flies, saw\n",
    "* **DET:** The, the, an\n",
    "* **ADP:** on, like, with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d44146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz (14.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy<3.8.0,>=3.7.4 (from en_core_sci_sm==0.5.4)\n",
      "  Using cached spacy-3.7.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.12)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4)\n",
      "  Using cached thinc-8.2.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.4.3)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.12.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2026.1.4)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4)\n",
      "  Using cached blis-0.7.11-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (14.2.0)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.21.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (7.5.0)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_core_sci_sm==0.5.4) (3.0.3)\n",
      "Using cached spacy-3.7.5-cp310-cp310-macosx_11_0_arm64.whl (6.6 MB)\n",
      "Using cached thinc-8.2.5-cp310-cp310-macosx_11_0_arm64.whl (779 kB)\n",
      "Using cached blis-0.7.11-cp310-cp310-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Installing collected packages: blis, thinc, spacy\n",
      "\u001b[2K  Attempting uninstall: blis\n",
      "\u001b[2K    Found existing installation: blis 1.3.3\n",
      "\u001b[2K    Uninstalling blis-1.3.3:\n",
      "\u001b[2K      Successfully uninstalled blis-1.3.3\n",
      "\u001b[2K  Attempting uninstall: thinc\n",
      "\u001b[2K    Found existing installation: thinc 8.3.10\n",
      "\u001b[2K    Uninstalling thinc-8.3.10:\n",
      "\u001b[2K      Successfully uninstalled thinc-8.3.10\n",
      "\u001b[2K  Attempting uninstall: spacy\n",
      "\u001b[2K    Found existing installation: spacy 3.8.11\n",
      "\u001b[2K    Uninstalling spacy-3.8.11:━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [spacy]\n",
      "\u001b[2K      Successfully uninstalled spacy-3.8.11m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [spacy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [spacy]32m2/3\u001b[0m [spacy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-0.7.11 spacy-3.7.5 thinc-8.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92dc2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "\n",
    "def run_spacy_analysis(sentence_list):\n",
    "    \"\"\"\n",
    "    Analyzes sentences using the standard English model (en_core_web_sm).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RUNNING: STANDARD SPACY (en_core_web_sm)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Model 'en_core_web_sm' not found. Please download it.\")\n",
    "        return\n",
    "\n",
    "    print(f\"{'TOKEN':<20} {'POS':<8} {'DESCRIPTION'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for text in sentence_list:\n",
    "        doc = nlp(text)\n",
    "        # Truncate long sentences for display\n",
    "        print(f\"\\nSentence: \\\"{text[:50]}...\\\"\")\n",
    "\n",
    "        for token in doc:\n",
    "            # token.pos_ returns the Universal Dependencies tag\n",
    "            description = spacy.explain(token.pos_) or \"No description\"\n",
    "            print(f\"{token.text:<20} {token.pos_:<8} {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba59ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scispacy_analysis(sentence_list):\n",
    "    \"\"\"\n",
    "    Analyzes sentences using the Biomedical model (en_core_sci_sm).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RUNNING: SCISPACY (en_core_sci_sm)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_sci_sm\")\n",
    "    except OSError:\n",
    "        print(\"Model 'en_core_sci_sm' not found. Please install it via pip.\")\n",
    "        return\n",
    "\n",
    "    print(f\"{'TOKEN':<20} {'POS':<8} {'DESCRIPTION'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for text in sentence_list:\n",
    "        doc = nlp(text)\n",
    "        print(f\"\\nSentence: \\\"{text[:50]}...\\\"\")\n",
    "\n",
    "        for token in doc:\n",
    "            # SciSpacy also uses Universal Dependencies\n",
    "            description = spacy.explain(token.pos_) or \"No description\"\n",
    "            print(f\"{token.text:<20} {token.pos_:<8} {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9cc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    # General\n",
    "    \"The cat sat on the couch\",\n",
    "    \"Time flies like an arrow\",\n",
    "    \"The spy saw the cop with the telescope\",\n",
    "    \"The spy saw the cop with the revolver\",\n",
    "    # Specific (Biology)\n",
    "    \"Arabidopsis thaliana seedlings exhibit longer hypocotyls when they are grown under high ambient temperature.\",\n",
    "    # Specific (Astronomy)\n",
    "    \"A spectrogram of PSN J10354824+3900279 obtained on Dec. 19.33 UT suggests that this is a type-Ia at redshift z 0.044.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d96fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUNNING: STANDARD SPACY (en_core_web_sm)\n",
      "============================================================\n",
      "TOKEN                POS      DESCRIPTION\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sentence: \"The cat sat on the couch...\"\n",
      "The                  DET      determiner\n",
      "cat                  NOUN     noun\n",
      "sat                  VERB     verb\n",
      "on                   ADP      adposition\n",
      "the                  DET      determiner\n",
      "couch                NOUN     noun\n",
      "\n",
      "Sentence: \"Time flies like an arrow...\"\n",
      "Time                 NOUN     noun\n",
      "flies                VERB     verb\n",
      "like                 ADP      adposition\n",
      "an                   DET      determiner\n",
      "arrow                NOUN     noun\n",
      "\n",
      "Sentence: \"The spy saw the cop with the telescope...\"\n",
      "The                  DET      determiner\n",
      "spy                  NOUN     noun\n",
      "saw                  VERB     verb\n",
      "the                  DET      determiner\n",
      "cop                  NOUN     noun\n",
      "with                 ADP      adposition\n",
      "the                  DET      determiner\n",
      "telescope            NOUN     noun\n",
      "\n",
      "Sentence: \"The spy saw the cop with the revolver...\"\n",
      "The                  DET      determiner\n",
      "spy                  NOUN     noun\n",
      "saw                  VERB     verb\n",
      "the                  DET      determiner\n",
      "cop                  NOUN     noun\n",
      "with                 ADP      adposition\n",
      "the                  DET      determiner\n",
      "revolver             NOUN     noun\n",
      "\n",
      "Sentence: \"Arabidopsis thaliana seedlings exhibit longer hypo...\"\n",
      "Arabidopsis          NOUN     noun\n",
      "thaliana             NOUN     noun\n",
      "seedlings            NOUN     noun\n",
      "exhibit              VERB     verb\n",
      "longer               ADV      adverb\n",
      "hypocotyls           NOUN     noun\n",
      "when                 SCONJ    subordinating conjunction\n",
      "they                 PRON     pronoun\n",
      "are                  AUX      auxiliary\n",
      "grown                VERB     verb\n",
      "under                ADP      adposition\n",
      "high                 ADJ      adjective\n",
      "ambient              ADJ      adjective\n",
      "temperature          NOUN     noun\n",
      ".                    PUNCT    punctuation\n",
      "\n",
      "Sentence: \"A spectrogram of PSN J10354824+3900279 obtained on...\"\n",
      "A                    DET      determiner\n",
      "spectrogram          NOUN     noun\n",
      "of                   ADP      adposition\n",
      "PSN                  PROPN    proper noun\n",
      "J10354824            PROPN    proper noun\n",
      "+                    PROPN    proper noun\n",
      "3900279              NUM      numeral\n",
      "obtained             VERB     verb\n",
      "on                   ADP      adposition\n",
      "Dec.                 PROPN    proper noun\n",
      "19.33                NUM      numeral\n",
      "UT                   PROPN    proper noun\n",
      "suggests             VERB     verb\n",
      "that                 SCONJ    subordinating conjunction\n",
      "this                 PRON     pronoun\n",
      "is                   AUX      auxiliary\n",
      "a                    DET      determiner\n",
      "type                 NOUN     noun\n",
      "-                    PUNCT    punctuation\n",
      "Ia                   NOUN     noun\n",
      "at                   ADP      adposition\n",
      "redshift             NOUN     noun\n",
      "z                    PROPN    proper noun\n",
      "0.044                NUM      numeral\n",
      ".                    PUNCT    punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sisso/documents_local/m2_ai/text_mining_and_chatbots/text_mining_1/.venv/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "run_spacy_analysis(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a1a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUNNING: SCISPACY (en_core_sci_sm)\n",
      "============================================================\n",
      "TOKEN                POS      DESCRIPTION\n",
      "------------------------------------------------------------\n",
      "\n",
      "Sentence: \"The cat sat on the couch...\"\n",
      "The                  DET      determiner\n",
      "cat                  NOUN     noun\n",
      "sat                  VERB     verb\n",
      "on                   ADP      adposition\n",
      "the                  DET      determiner\n",
      "couch                NOUN     noun\n",
      "\n",
      "Sentence: \"Time flies like an arrow...\"\n",
      "Time                 NOUN     noun\n",
      "flies                NOUN     noun\n",
      "like                 ADP      adposition\n",
      "an                   DET      determiner\n",
      "arrow                NOUN     noun\n",
      "\n",
      "Sentence: \"The spy saw the cop with the telescope...\"\n",
      "The                  DET      determiner\n",
      "spy                  NOUN     noun\n",
      "saw                  VERB     verb\n",
      "the                  DET      determiner\n",
      "cop                  NOUN     noun\n",
      "with                 ADP      adposition\n",
      "the                  DET      determiner\n",
      "telescope            NOUN     noun\n",
      "\n",
      "Sentence: \"The spy saw the cop with the revolver...\"\n",
      "The                  DET      determiner\n",
      "spy                  NOUN     noun\n",
      "saw                  VERB     verb\n",
      "the                  DET      determiner\n",
      "cop                  NOUN     noun\n",
      "with                 ADP      adposition\n",
      "the                  DET      determiner\n",
      "revolver             NOUN     noun\n",
      "\n",
      "Sentence: \"Arabidopsis thaliana seedlings exhibit longer hypo...\"\n",
      "Arabidopsis          NOUN     noun\n",
      "thaliana             NOUN     noun\n",
      "seedlings            NOUN     noun\n",
      "exhibit              VERB     verb\n",
      "longer               ADV      adverb\n",
      "hypocotyls           ADJ      adjective\n",
      "when                 SCONJ    subordinating conjunction\n",
      "they                 PRON     pronoun\n",
      "are                  AUX      auxiliary\n",
      "grown                VERB     verb\n",
      "under                ADP      adposition\n",
      "high                 ADJ      adjective\n",
      "ambient              ADJ      adjective\n",
      "temperature          NOUN     noun\n",
      ".                    PUNCT    punctuation\n",
      "\n",
      "Sentence: \"A spectrogram of PSN J10354824+3900279 obtained on...\"\n",
      "A                    DET      determiner\n",
      "spectrogram          NOUN     noun\n",
      "of                   ADP      adposition\n",
      "PSN                  NOUN     noun\n",
      "J10354824            NOUN     noun\n",
      "+                    CCONJ    coordinating conjunction\n",
      "3900279              NUM      numeral\n",
      "obtained             VERB     verb\n",
      "on                   ADP      adposition\n",
      "Dec.                 PROPN    proper noun\n",
      "19.33                NUM      numeral\n",
      "UT                   PROPN    proper noun\n",
      "suggests             VERB     verb\n",
      "that                 SCONJ    subordinating conjunction\n",
      "this                 DET      determiner\n",
      "is                   AUX      auxiliary\n",
      "a                    DET      determiner\n",
      "type-Ia              NOUN     noun\n",
      "at                   ADP      adposition\n",
      "redshift             NOUN     noun\n",
      "z                    NOUN     noun\n",
      "0.044                NUM      numeral\n",
      ".                    PUNCT    punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sisso/documents_local/m2_ai/text_mining_and_chatbots/text_mining_1/.venv/lib/python3.10/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_scispacy_analysis(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020227e",
   "metadata": {},
   "source": [
    "# `Part 2 : Syntactic Parsing` \n",
    "### Parsing using NLTK Chat Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd92441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsing: 'The cat sat on the couch'\n",
      "--------------------------------------------------\n",
      "Tree #1:\n",
      "              S                        \n",
      "      ________|________                 \n",
      "     |                 VP              \n",
      "     |         ________|___             \n",
      "     |        |            PP          \n",
      "     |        |     _______|___         \n",
      "     NP       |    |           NP      \n",
      "  ___|___     |    |        ___|____    \n",
      "DET     NOUN VERB ADP     DET      NOUN\n",
      " |       |    |    |       |        |   \n",
      "The     cat  sat   on     the     couch\n",
      "\n",
      "\n",
      "Parsing: 'Time flies like an arrow'\n",
      "--------------------------------------------------\n",
      "Tree #1:\n",
      "            S                    \n",
      "  __________|____                 \n",
      " |               VP              \n",
      " |      _________|___             \n",
      " |     |             PP          \n",
      " |     |     ________|___         \n",
      " |     |    |            NP      \n",
      " |     |    |         ___|____    \n",
      " NP   VERB ADP      DET      NOUN\n",
      " |     |    |        |        |   \n",
      "Time flies like      an     arrow\n",
      "\n",
      "\n",
      "Parsing: 'The spy saw the cop with the telescope'\n",
      "--------------------------------------------------\n",
      "Tree #1:\n",
      "                   S                                 \n",
      "      _____________|_______                           \n",
      "     |                     VP                        \n",
      "     |              _______|_________                 \n",
      "     |             VP                PP              \n",
      "     |         ____|___          ____|___             \n",
      "     NP       |        NP       |        NP          \n",
      "  ___|___     |     ___|___     |     ___|______      \n",
      "DET     NOUN VERB DET     NOUN ADP  DET        NOUN  \n",
      " |       |    |    |       |    |    |          |     \n",
      "The     spy  saw  the     cop  with the     telescope\n",
      "\n",
      "Tree #2:\n",
      "                   S                                 \n",
      "      _____________|_______                           \n",
      "     |                     VP                        \n",
      "     |         ____________|____                      \n",
      "     |        |                 NP                   \n",
      "     |        |         ________|____                 \n",
      "     |        |        |             PP              \n",
      "     |        |        |         ____|___             \n",
      "     NP       |        NP       |        NP          \n",
      "  ___|___     |     ___|___     |     ___|______      \n",
      "DET     NOUN VERB DET     NOUN ADP  DET        NOUN  \n",
      " |       |    |    |       |    |    |          |     \n",
      "The     spy  saw  the     cop  with the     telescope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "\n",
    "grammar_text = \"\"\"\n",
    "    S   -> NP VP\n",
    "\n",
    "    VP  -> VERB NP\n",
    "    VP  -> VP PP\n",
    "    VP  -> VERB PP\n",
    "\n",
    "    NP  -> DET NOUN\n",
    "    NP  -> NP PP\n",
    "    NP  -> 'Time'\n",
    "\n",
    "    PP  -> ADP NP\n",
    "\n",
    "    # Lexicon (Handling Ambiguities)\n",
    "    DET  -> 'The' | 'the' | 'an' | 'a'\n",
    "    NOUN -> 'cat' | 'couch' | 'Time' | 'flies' | 'arrow' | 'spy' | 'cop' | 'telescope' | 'revolver'\n",
    "    VERB -> 'sat' | 'flies' | 'like' | 'saw'\n",
    "    ADP  -> 'on' | 'like' | 'with'\n",
    "\"\"\"\n",
    "\n",
    "grammar = CFG.fromstring(grammar_text)\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "\n",
    "def parse_sentence(sentence):\n",
    "    tokens = sentence.split()\n",
    "    print(f\"\\nParsing: '{sentence}'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Attempt to parse\n",
    "    try:\n",
    "        trees = list(parser.parse(tokens))\n",
    "    except ValueError:\n",
    "        print(\"Tokens contain words not in grammar.\")\n",
    "        return\n",
    "\n",
    "    if not trees:\n",
    "        print(\"No parse found (Grammar structure mismatch).\")\n",
    "\n",
    "    for i, tree in enumerate(trees):\n",
    "        print(f\"Tree #{i+1}:\")\n",
    "        tree.pretty_print()\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"The cat sat on the couch\",\n",
    "    \"Time flies like an arrow\",\n",
    "    \"The spy saw the cop with the telescope\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    parse_sentence(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426831df",
   "metadata": {},
   "source": [
    "### Parsing using CYK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403aa022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The cat sat on the couch\n",
      "S\n",
      "----NP\n",
      "--------DET - The\n",
      "--------NOUN - cat\n",
      "----VP\n",
      "--------VERB - sat\n",
      "--------PP\n",
      "------------PREP - on\n",
      "------------NP\n",
      "----------------DET - the\n",
      "----------------NOUN - couch\n",
      "\n",
      "\n",
      "S\n",
      "----NP\n",
      "--------DET - The\n",
      "--------NOUN - cat\n",
      "----VP\n",
      "--------VP - sat\n",
      "--------PP\n",
      "------------PREP - on\n",
      "------------NP\n",
      "----------------DET - the\n",
      "----------------NOUN - couch\n",
      "\n",
      "\n",
      "Nb parses: 2\n",
      "Sentence: Time flies like an arrow\n",
      "S\n",
      "----NP - Time\n",
      "----VP\n",
      "--------VERB - flies\n",
      "--------PP\n",
      "------------PREP - like\n",
      "------------NP\n",
      "----------------DET - an\n",
      "----------------NOUN - arrow\n",
      "\n",
      "\n",
      "S\n",
      "----NP - Time\n",
      "----VP\n",
      "--------VP - flies\n",
      "--------PP\n",
      "------------PREP - like\n",
      "------------NP\n",
      "----------------DET - an\n",
      "----------------NOUN - arrow\n",
      "\n",
      "\n",
      "Nb parses: 2\n",
      "Sentence: The spy saw the cop with the telescope\n",
      "S\n",
      "----NP\n",
      "--------DET - The\n",
      "--------NOUN - spy\n",
      "----VP\n",
      "--------VERB - saw\n",
      "--------NP\n",
      "------------NP\n",
      "----------------DET - the\n",
      "----------------NOUN - cop\n",
      "------------PP\n",
      "----------------PREP - with\n",
      "----------------NP\n",
      "--------------------DET - the\n",
      "--------------------NOUN - telescope\n",
      "\n",
      "\n",
      "S\n",
      "----NP\n",
      "--------DET - The\n",
      "--------NOUN - spy\n",
      "----VP\n",
      "--------VP\n",
      "------------VERB - saw\n",
      "------------NP\n",
      "----------------DET - the\n",
      "----------------NOUN - cop\n",
      "--------PP\n",
      "------------PREP - with\n",
      "------------NP\n",
      "----------------DET - the\n",
      "----------------NOUN - telescope\n",
      "\n",
      "\n",
      "Nb parses: 2\n"
     ]
    }
   ],
   "source": [
    "from cyk import parse_sentence_cyk\n",
    "pos_lists = [\n",
    "\n",
    "    #The cat sat on the couch\n",
    "    [\n",
    "        [\"DET\"],          \n",
    "        [\"NOUN\"],         \n",
    "        [\"VERB\"],         \n",
    "        [\"PREP\"],         \n",
    "        [\"DET\"],          \n",
    "        [\"NOUN\"]         \n",
    "    ],\n",
    "\n",
    "    #Time flies like an arrow\n",
    "    [\n",
    "        [\"NOUN\"],                 \n",
    "        [\"NOUN\", \"VERB\"],         # flies \n",
    "        [\"PREP\", \"VERB\"],         # like \n",
    "        [\"DET\"],                  \n",
    "        [\"NOUN\"]                  \n",
    "    ],\n",
    "    #The spy saw the cop with the telescope\n",
    "    [\n",
    "        [\"DET\"],          \n",
    "        [\"NOUN\"],         \n",
    "        [\"VERB\"],         \n",
    "        [\"DET\"],          \n",
    "        [\"NOUN\"],         \n",
    "        [\"PREP\"],        \n",
    "        [\"DET\"],         \n",
    "        [\"NOUN\"]          \n",
    "    ]\n",
    "]\n",
    "for sentence, pos in zip(sentences, pos_lists):\n",
    "\n",
    "    print(\"Sentence:\", sentence)\n",
    "    parse_sentence_cyk(sentence, pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f60c8",
   "metadata": {},
   "source": [
    "### Comparison with Spacy Syntactic analysis(constituency parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52cd39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en3 to\n",
      "[nltk_data]     /Users/sisso/nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n",
      "/Users/sisso/documents_local/m2_ai/text_mining_and_chatbots/text_mining_1/.venv/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/sisso/documents_local/m2_ai/text_mining_and_chatbots/text_mining_1/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x131f0f430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import benepar, spacy\n",
    "benepar.download('benepar_en3')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d637fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence_constituency(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    sent = list(doc.sents)[0]\n",
    "    print(sent._.parse_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2784073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (DT The) (NN cat)) (VP (VBD sat) (PP (IN on) (NP (DT the) (NN couch)))))\n",
      "(S (NP (NN Time)) (VP (VBZ flies) (PP (IN like) (NP (DT an) (NN arrow)))))\n",
      "(S (NP (DT The) (NN spy)) (VP (VBD saw) (NP (DT the) (NN cop)) (PP (IN with) (NP (DT the) (NN telescope)))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sisso/documents_local/m2_ai/text_mining_and_chatbots/text_mining_1/.venv/lib/python3.10/site-packages/torch/distributions/distribution.py:62: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The cat sat on the couch\",\n",
    "    \"Time flies like an arrow\",\n",
    "    \"The spy saw the cop with the telescope\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    parse_sentence_constituency(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa4f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
